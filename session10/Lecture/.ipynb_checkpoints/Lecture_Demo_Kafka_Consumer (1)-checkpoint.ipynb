{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "topic = 'LectureDemoWeek10'\n",
    "hash_table_R = {}\n",
    "hash_table_S = {}\n",
    "\n",
    "def connect_kafka_consumer():\n",
    "    _consumer = None\n",
    "    try:\n",
    "         _consumer = KafkaConsumer(topic,\n",
    "                                   consumer_timeout_ms=10000, # stop iteration if no message after 10 sec\n",
    "                                   auto_offset_reset='latest', # comment this if you don't want to consume latest available message\n",
    "                                   bootstrap_servers=['localhost:9092'],\n",
    "                                   api_version=(0, 10))\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _consumer\n",
    "\n",
    "def consume_messages(consumer):\n",
    "    try:\n",
    "        for message in consumer:\n",
    "            data = str(message.value.decode('utf-8')).split(',')\n",
    "            table = data[0]\n",
    "            key = data[1]\n",
    "            value = data[2]\n",
    "            # Implementation of bounded Symmetric Hash Join\n",
    "            if table == 'R':\n",
    "                # Step 1: Probe tuple into hash table S\n",
    "                if key in hash_table_S:\n",
    "                    matching_records = []\n",
    "                    for values in hash_table_S[key]:\n",
    "                        if key == values[0]:\n",
    "                            matching_records.append([key, value, values[1]])\n",
    "                    # Step 2: Show the join results\n",
    "                    print(matching_records)\n",
    "                # Step 3: Hash tuple into hash table R\n",
    "                if key in hash_table_R:\n",
    "                    hash_table_R[key].append([key,value])\n",
    "                else:\n",
    "                    hash_table_R[key] = []\n",
    "                    hash_table_R[key].append([key,value])\n",
    "                    \n",
    "            else:\n",
    "                # Step 1: Probe tuple into hash table R\n",
    "                if key in hash_table_R:\n",
    "                    matching_records = []\n",
    "                    for values in hash_table_R[key]:\n",
    "                        if key == values[0]:\n",
    "                            matching_records.append([key, value, values[1]])\n",
    "                    # Step 2: Show the join results\n",
    "                    print(matching_records)\n",
    "                # Step 3: Hash tuple into hash table S\n",
    "                if key in hash_table_S:\n",
    "                    hash_table_S[key].append([key,value])\n",
    "                else:\n",
    "                    hash_table_S[key] = []\n",
    "                    hash_table_S[key].append([key,value])\n",
    "                    \n",
    "    except Exception as ex:\n",
    "        print(str(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = connect_kafka_consumer()\n",
    "consume_messages(consumer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
